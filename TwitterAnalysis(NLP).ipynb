{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq3Dtl6B2Qv9p/pCyNdHu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishsingh-del/NLP-Tasks/blob/main/TwitterAnalysis(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thdH6ljJzBG3",
        "outputId": "02a6a871-ec64-4aa3-a094-96ead2c73e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pyspellchecker-0.8.3-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.3\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "!pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "# Sample Twitter data with emojis, hashtags, and misspellings\n",
        "data = {\n",
        "    'tweet': [\n",
        "        'I am sooooo excited for the weekend! ðŸŽ‰',\n",
        "        'Just finished my #DataScience project. So happy!! ðŸ˜Š',\n",
        "        'This is the best movie everrr ðŸ’¯. #movies',\n",
        "        'wht a gr8 day to be alive #blessed',\n",
        "        'I luv my new phone! ðŸ“± so fast omg'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmrDzgjQzNzj",
        "outputId": "f60e9672-24af-4a0d-cdf6-539d4a558701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "                                               tweet\n",
            "0             I am sooooo excited for the weekend! ðŸŽ‰\n",
            "1  Just finished my #DataScience project. So happ...\n",
            "2           This is the best movie everrr ðŸ’¯. #movies\n",
            "3                 wht a gr8 day to be alive #blessed\n",
            "4                  I luv my new phone! ðŸ“± so fast omg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove emojis\n",
        "def remove_emojis(text):\n",
        "    return emoji.replace_emoji(text, replace='')\n",
        "\n",
        "# Function to convert emojis to text\n",
        "def convert_emojis_to_text(text):\n",
        "    return emoji.demojize(text, delimiters=(\"\", \" \"))\n",
        "\n",
        "# Function to process hashtags\n",
        "def process_hashtags(text):\n",
        "    # Remove '#' and keep the word\n",
        "    text = re.sub(r'#', '', text)\n",
        "    # Simple split of concatenated words (e.g., #DataScience becomes Data Science)\n",
        "    # A more advanced method would use a dedicated library\n",
        "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
        "    return text\n",
        "\n",
        "# Function to correct spelling\n",
        "def correct_spelling(text):\n",
        "    spell = SpellChecker()\n",
        "    words = text.split()\n",
        "    corrected_words = []\n",
        "    for word in words:\n",
        "        corrected = spell.correction(word)\n",
        "        if corrected is not None:\n",
        "            corrected_words.append(corrected)\n",
        "        else:\n",
        "            corrected_words.append(word)\n",
        "    return ' '.join(corrected_words)\n",
        "\n",
        "# Function to handle repeated letters (e.g., \"sooooo\" -> \"sooo\")\n",
        "def handle_repeated_letters(text):\n",
        "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "\n",
        "# Function to expand common slang/abbreviations\n",
        "def expand_slang(text):\n",
        "    slang_dict = {\n",
        "        'lol': 'laughing out loud',\n",
        "        'omg': 'oh my god',\n",
        "        'luv': 'love',\n",
        "        'wht': 'what',\n",
        "        'gr8': 'great'\n",
        "    }\n",
        "    words = text.split()\n",
        "    expanded_words = [slang_dict.get(word.lower(), word) for word in words]\n",
        "    return ' '.join(expanded_words)"
      ],
      "metadata": {
        "id": "pqIr2-FBzOee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame to store the cleaned text\n",
        "df_cleaned = df.copy()\n",
        "\n",
        "# Step 1: Expand slang and handle repeated letters\n",
        "df_cleaned['tweet'] = df_cleaned['tweet'].apply(expand_slang)\n",
        "df_cleaned['tweet'] = df_cleaned['tweet'].apply(handle_repeated_letters)\n",
        "print(\"\\nAfter slang expansion and repeated letter handling:\")\n",
        "print(df_cleaned)\n",
        "\n",
        "# Step 2: Convert emojis to text for sentiment analysis\n",
        "df_cleaned['tweet'] = df_cleaned['tweet'].apply(convert_emojis_to_text)\n",
        "print(\"\\nAfter converting emojis to text:\")\n",
        "print(df_cleaned)\n",
        "\n",
        "# Step 3: Process hashtags (remove '#' and split words)\n",
        "df_cleaned['tweet'] = df_cleaned['tweet'].apply(process_hashtags)\n",
        "print(\"\\nAfter processing hashtags:\")\n",
        "print(df_cleaned)\n",
        "\n",
        "# Step 4: Correct misspellings\n",
        "df_cleaned['tweet'] = df_cleaned['tweet'].apply(correct_spelling)\n",
        "print(\"\\nFinal Cleaned DataFrame:\")\n",
        "print(df_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtGYE-WMzv03",
        "outputId": "d34d78c5-b3ed-4e26-a089-9511c4c9b67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After slang expansion and repeated letter handling:\n",
            "                                               tweet\n",
            "0                I am soo excited for the weekend! ðŸŽ‰\n",
            "1  Just finished my #DataScience project. So happ...\n",
            "2            This is the best movie everr ðŸ’¯. #movies\n",
            "3              what a great day to be alive #blessed\n",
            "4           I love my new phone! ðŸ“± so fast oh my god\n",
            "\n",
            "After converting emojis to text:\n",
            "                                               tweet\n",
            "0    I am soo excited for the weekend! party_popper \n",
            "1  Just finished my #DataScience project. So happ...\n",
            "2  This is the best movie everr hundred_points . ...\n",
            "3              what a great day to be alive #blessed\n",
            "4  I love my new phone! mobile_phone  so fast oh ...\n",
            "\n",
            "After processing hashtags:\n",
            "                                               tweet\n",
            "0    I am soo excited for the weekend! party_popper \n",
            "1  Just finished my Data Science project. So happ...\n",
            "2  This is the best movie everr hundred_points . ...\n",
            "3               what a great day to be alive blessed\n",
            "4  I love my new phone! mobile_phone  so fast oh ...\n",
            "\n",
            "Final Cleaned DataFrame:\n",
            "                                               tweet\n",
            "0       I am so excited for the weekend party_popper\n",
            "1  Just finished my Data Science project So happy...\n",
            "2  This is the best movie ever hundred_points . m...\n",
            "3               what a great day to be alive blessed\n",
            "4  I love my new phone mobile_phone so fast oh my...\n"
          ]
        }
      ]
    }
  ]
}